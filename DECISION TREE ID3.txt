import pandas as pd
import numpy as np


# Step 1: Calculate Entropy
def entropy(target_col):
    elements, counts = np.unique(target_col, return_counts=True)
    entropy_value = np.sum([-counts[i] / np.sum(counts) * np.log2(counts[i] / np.sum(counts)) for i in range(len(elements))])
    return entropy_value


# Step 2: Calculate Information Gain
def info_gain(data, split_attribute_name, target_name="PlayTennis"):
    total_entropy = entropy(data[target_name])
    vals, counts = np.unique(data[split_attribute_name], return_counts=True)
    weighted_entropy = np.sum([(counts[i] / np.sum(counts)) * entropy(data.where(data[split_attribute_name] == vals[i]).dropna()[target_name]) for i in range(len(vals))])
    information_gain = total_entropy - weighted_entropy
    return information_gain


# Step 3: ID3 Algorithm to build the tree
def ID3(data, original_data, features, target_attribute_name="PlayTennis", parent_node_class=None):
    if len(np.unique(data[target_attribute_name])) <= 1:
        return np.unique(data[target_attribute_name])[0]
    elif len(data) == 0:
        return np.unique(original_data[target_attribute_name])[np.argmax(np.unique(original_data[target_attribute_name], return_counts=True)[1])]
    elif len(features) == 0:
        return parent_node_class
    else:
        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name], return_counts=True)[1])]
        item_values = [info_gain(data, feature, target_attribute_name) for feature in features]
        best_feature_index = np.argmax(item_values)
        best_feature = features[best_feature_index]


        tree = {best_feature: {}}
        features = [i for i in features if i != best_feature]


        for value in np.unique(data[best_feature]):
            sub_data = data.where(data[best_feature] == value).dropna()
            subtree = ID3(sub_data, original_data, features, target_attribute_name, parent_node_class)
            tree[best_feature][value] = subtree


        return tree


# Function to classify a new sample
def classify(sample, tree):
    for key in tree.keys():
        value = sample[key]
        tree = tree[key][value]
        if isinstance(tree, dict):
            return classify(sample, tree)
        else:
            return tree


# Step 4: Load the dataset from CSV
df = pd.read_csv('enjoysportID3.csv')


# Step 5: Run the ID3 algorithm
features = list(df.columns[:-1])
tree = ID3(df, df, features)


# Print the decision tree
import pprint
pprint.pprint(tree)


# Step 6: Classify a new sample
new_sample = {
    'Outlook': 'Sunny',
    'Temperature': 'Hot',
    'Humidity': 'High',
    'Wind': 'Strong',
}


classification = classify(new_sample, tree)
print(f"The new sample is classified as: {classification}")